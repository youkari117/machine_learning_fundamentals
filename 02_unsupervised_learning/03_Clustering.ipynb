{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e44c4e6",
   "metadata": {},
   "source": [
    "<h1>k-means</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4b5e7",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f36299",
   "metadata": {},
   "source": [
    "<h4>概要</h4>\n",
    "k-meansクラスタリングは、データのある領域を代表するようなクラスタ重心を見つけようとする<br>\n",
    "1.個々のデータポイントを最寄りのクラスタ重心に割り当てる（最初はクラスタ数分のデータポイントをクラスタセンタとして乱数で選ぶ）<br>\n",
    "2.個々のクラスタ重心をその点に割り当てられたデータポイントの平均に設定する<br>\n",
    "3.データポイントの割り当てが変化しなくなったら、アルゴリズムは終了する<br>\n",
    "新しいデータポイントが与えらえると、k-meansは、クラスタセンタのうち、最も近いものに割り当てる<br>\n",
    "クラスタリングとクラス分類は、両方ともラベル付けするという意味で、ある意味似ているが、クラスタリングには真のラベルというものがないので、\n",
    "付いたラベルには先験的な意味はない<br>\n",
    "k-meansの欠点の一つは、初期化が乱数で行われることだ。これは、アルゴリズムの出力が乱数のシードに依存することを意味する<br>\n",
    "sckit-learnではデフォルトで、異なる乱数を用いてアルゴリズムを10回実行し、<b>慣性</b>（各インスタンスと最近傍重心の平均二乗距離）が最小のモデルを返してくる。アルゴリズムの実行回数は<b>n_init</b>で指定できる。また、慣性は<b>inertia_</b>属性に格納されている。一方でscore()でメソッドは負の慣性を返す（予測器のscore()メソッドはsklearnの「大きいものはいいものだ」というルールに従わなければならないため）<br>\n",
    "さらなる欠点は、k-meansがクラスタの形に対してかなり制約の強い仮定を置いていることと、クラスタ数をユーザが指定しなければならないことである\n",
    "\n",
    "<h4>基本</h4>\n",
    "<b>KMeans</b>クラスのインスタンスを生成し、作りたいクラスタの数(<b>n_clusters</b>)を設定する（デフォルトは8つ）<br>\n",
    "個々の訓練データポイントに割り当てられたラベルは<b>kmeans.labels_</b>属性で確認できる<br>\n",
    "<b>predict</b>メソッドを用いて、新しいデータポイントにクラスタを割り当てることができる。新しいデータポイントは、最も近いクラスタセンタに割り当てられるが、既存のモデルは変更されない<br>\n",
    "クラスタセンタは<b>cluster_centers_</b>属性に格納されている\n",
    "\n",
    "<h4>k-meansがうまくいかない場合</h4>\n",
    "それぞれのクラスタは、重心だけで定義されているため、k-meansでは比較的単純な形しか見つけられない<br>\n",
    "また、k-meansでは、クラスタ境界をクラスタセンタのちょうど中間に引く<br>\n",
    "k-meansはクラスタに関してすべての方向が同じように重要であることを仮定する<br>\n",
    "言い換えれば、k-meansは丸くないクラスタを識別できない<br>\n",
    "k-meansは、クラスタが複雑な形の場合にもうまく機能しない<br>\n",
    "k-meansを実行する前に入力特徴量をスケーリングすることが大切である。スケーリングしなければクラスタが細長くなって、k-meansではうまく処理できなくなる。特徴量をスケーリングしたからと言って、すべてのクラスタがうまく円形になるわけではないが、それでも得られる効果は大きい\n",
    "\n",
    "<h4>ベクトル量子化</h4>\n",
    "k-meansとPCAやNMFなどの成分分解手法の間には興味深い類似性がある<br>\n",
    "PCAは、データ中の最も分散が大きい方向群(極端な特徴)を見出そうとし、NMFは足しこんでいくことのできる成分(部品)を見つけようとしていた<br>\n",
    "PCAとNMFは、データポイントを複数の成分の和として表現しようとする<br>\n",
    "k-meansは、個々のデータポイントを、クラスタセンタとして与えらえる単一の成分で表現していると考えることができる<br>\n",
    "このように、k-meansを単一成分で個々のデータポイントを表現する成分分解手法としてみる考え方を、<b>ベクトル量子化</b>と呼ぶ\n",
    "\n",
    "<h4>transform()メソッド</h4>\n",
    "個々のインスタンスにひとつのクラスタを与える（ハードクラスタリング）のではなく、各インスタンスにクラスタごとのスコアを与える（ソフトクラスタリング）とよい場合がある。KMeansクラスの<b>transform()</b>メソッドは、インスタンスと各重心の距離を計測する。これはクラスタ数がk個ならば、データをk次元へ変換する。つまり、高次元データセットを<b>transform()</b>メソッドで変換すると、k次元のデータセットになり、この変換は、効率のよい非線形次元削減テクニックになる\n",
    "\n",
    "<h4>重心の初期化方法</h4>\n",
    "初期の個々の重心が離れた位置になるように選ぶアルゴリズム（k-means++）がある。これによりk-meansは非最適解に収束しにくくなる。KMeansクラスは、デフォルトでこの初期化方法を使っている。また、例えば、重心をどこにすべきかおおよその位置がわかっているのであれば（例えば、既に別のクラスタリングアルゴリズムを実行しているなど）、initハイパーパラメータに重心のリストを格納したNumPy配列を指定し、n_initハイパーパラメータを1にすればよい<br>\n",
    "good_init = np.array([[-3,3],[-3,2],[-3,1],[-1,2],[0,2]])<br>\n",
    "kmeans = KMeans(n_clusters = 5, init = good_init, n_init = 1)\n",
    "\n",
    "<h4>ミニバッチk-means</h4>\n",
    "MiniBatchKMeansクラスは、メモリに入りきらない巨大データセットをクラスタリングでき、アルゴリズムは3倍から4倍高速になるが、慣性の品質は一般に通常のk-meansよりもほんのわずかに劣る。特に、クラスタ数が増えると見劣りしてくる<br>\n",
    "from sklearn.cluster import MiniBatchKMeans<br>\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters = 5)<br>\n",
    "minibatch_kmeans.fit(X)\n",
    "\n",
    "<h4>最適なクラスタ数の見つけ方</h4>\n",
    "最適なクラスタ数を見つけるのに、慣性が最も小さいモデルを選ぶ、というのは間違っている。実際、慣性はクラスタ数を大きくしていくと小さくなる一方である。なぜなら、クラスタ数が増えれば増えるほど、個々のインスタンスにとって最も近い重心はどんどん近付いてくるはずであり、慣性も小さくなる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2251ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f0f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_kmeans_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767944a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_kmeans_boundaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X, y = make_blobs(random_state = 1)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "kmeans = KMeans(n_clusters= 3)\n",
    "kmeans.fit(X)\n",
    "print(f\"Cluster memberships:\\n{kmeans.labels_}\")\n",
    "print(kmeans.predict(X))\n",
    "print(np.all(kmeans.labels_ == kmeans.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.discrete_scatter(X[:,0],X[:,1], kmeans.labels_, markers = \"o\")\n",
    "mglearn.discrete_scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], [0,1,2], markers = \"^\", markeredgewidth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fdee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize = (10, 5))\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(X)\n",
    "assignments = kmeans.labels_\n",
    "mglearn.discrete_scatter(X[:,0], X[:,1], assignments, ax = axes[0])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 5)\n",
    "kmeans.fit(X)\n",
    "assignments = kmeans.labels_\n",
    "mglearn.discrete_scatter(X[:,0], X[:,1], assignments, ax = axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9773b2",
   "metadata": {},
   "source": [
    "<h3>k-meansがうまくいかない場合</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea872735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記例だと、cluster0やcluster1の真ん中の方の点は、直感的には、cluster2に分類されそうではある\n",
    "X_varied, y_varied = make_blobs(n_samples = 200, cluster_std = [1.0, 2.5, 0.5], random_state = 170)\n",
    "y_pred = KMeans(n_clusters = 3, random_state = 0).fit_predict(X_varied)\n",
    "\n",
    "mglearn.discrete_scatter(X_varied[:,0], X_varied[:,1], y_pred)\n",
    "plt.legend([\"cluster 0\",\"cluster 1\",\"cluster 2\"], loc = \"best\")\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記例は、対角線方向にデータが伸ばされているが、k-meansは最も近いクラスタセンタへの距離しか考慮しないので、\n",
    "# このようなデータは取り扱えない\n",
    "X, y = make_blobs(random_state = 170, n_samples = 600)\n",
    "rng = np.random.RandomState(74)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "transformation = rng.normal(size = (2,2))\n",
    "X = np.dot(X, transformation)\n",
    "print(X.shape)\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c = y_pred, cmap = mglearn.cm3)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], marker = \"^\", c = [0,1,2], s = 100, linewidth = 2, cmap = mglearn.cm3)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120bf147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples = 200, noise = 0.05, random_state = 0)\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1], c = y_pred, cmap = mglearn.cm2, s = 60)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],\n",
    "            marker = \"^\", c = [mglearn.cm2(0), mglearn.cm2(1)], s = 100, linewidth = 2)\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063ff93",
   "metadata": {},
   "source": [
    "<h3>ベクトル量子化、もしくは成分分解としてのk-means</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA,NMF,k-meansを抽出された成分で比較する\n",
    "# さらに、100成分を用いた再構成画像も比較する。k-meansの再構成画像には、訓練セットから得られたクラスタセンタのうち最も近いものを用いる\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "people = fetch_lfw_people(min_faces_per_person = 20, resize = 0.7)\n",
    "image_shape = people.images[0].shape\n",
    "\n",
    "mask = np.zeros(people.target.shape, dtype = np.bool_)\n",
    "for target in np.unique(people.target):\n",
    "    mask[np.where(people.target == target)[0][:50]] = 1\n",
    "\n",
    "X_people = people.data[mask]\n",
    "y_people = people.target[mask]\n",
    "X_people = X_people/255\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_people, y_people, stratify = y_people, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "nmf = NMF(n_components = 100, random_state = 0).fit(X_train)\n",
    "pca = PCA(n_components = 100, random_state = 0).fit(X_train)\n",
    "kmeans = KMeans(n_clusters = 100, random_state = 0).fit(X_train)\n",
    "\n",
    "X_reconstructed_pca = pca.inverse_transform(pca.transform(X_test))\n",
    "print(X_reconstructed_pca.shape)\n",
    "X_reconstructed_kmeans = kmeans.cluster_centers_[kmeans.predict(X_test)]\n",
    "print(X_reconstructed_kmeans.shape)\n",
    "X_reconstructed_nmf = np.dot(nmf.transform(X_test), nmf.components_)\n",
    "print(nmf.components_.shape)\n",
    "print(X_reconstructed_nmf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 5, figsize = (8, 8), subplot_kw = {\"xticks\":(),\"yticks\":()})\n",
    "fig.suptitle(\"Extracted Components\")\n",
    "print(axes.T)\n",
    "for ax, comp_kmeans, comp_pca, comp_nmf in zip(axes.T, kmeans.cluster_centers_, pca.components_, nmf.components_):\n",
    "    ax[0].imshow(comp_kmeans.reshape(image_shape))\n",
    "    ax[1].imshow(comp_pca.reshape(image_shape))\n",
    "    ax[2].imshow(comp_nmf.reshape(image_shape))\n",
    "\n",
    "axes[0, 0].set_ylabel(\"kmeans\")\n",
    "axes[1, 0].set_ylabel(\"pca\")\n",
    "axes[2, 0].set_ylabel(\"nmf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d859bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, subplot_kw = {\"xticks\":(),\"yticks\":()}, figsize = (8, 8))\n",
    "fig.suptitle(\"Reconstructions\")\n",
    "for ax, orig, rec_kmeans, rec_pca, rec_nmf in zip(axes.T, X_test, X_reconstructed_kmeans, X_reconstructed_pca, X_reconstructed_nmf):\n",
    "    ax[0].imshow(orig.reshape(image_shape))\n",
    "    ax[1].imshow(rec_kmeans.reshape(image_shape))\n",
    "    ax[2].imshow(rec_pca.reshape(image_shape))\n",
    "    ax[3].imshow(rec_nmf.reshape(image_shape))\n",
    "\n",
    "axes[0, 0].set_ylabel(\"original\")\n",
    "axes[1, 0].set_ylabel(\"kmeans\")\n",
    "axes[2, 0].set_ylabel(\"pca\")\n",
    "axes[3, 0].set_ylabel(\"nmf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記では10のクラスタセンタを用いている。これを、10成分でのデータ表現と考えることができる\n",
    "# この10次元表現を使えば、この2つの半月型を線形モデルで分離できる\n",
    "X, y = make_moons(n_samples = 200, noise = 0.05, random_state = 0)\n",
    "kmeans = KMeans(n_clusters = 10, random_state = 0).fit(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c = y_pred, s = 60, cmap = \"Paired\")\n",
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],\n",
    "            s = 60, marker = \"^\", c = range(kmeans.n_clusters), linewidth = 2, cmap = \"Paired\")\n",
    "plt.xlabel(\"Feature 0\")\n",
    "plt.ylabel(\"Feature 1\")\n",
    "print(f\"Cluster memberships:\\n{y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform()メソッド\n",
    "print(X.shape)\n",
    "distance_features = kmeans.transform(X)\n",
    "print(f\"Distance feature shape: {distance_features.shape}\")\n",
    "print(f\"Distance features:\\n{distance_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424d4b7",
   "metadata": {},
   "source": [
    "<h3>最適なクラスタ数の見つけ方</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])\n",
    "\n",
    "X, y = make_blobs(n_samples=2000, centers=blob_centers, cluster_std=blob_std, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans_k3.inertia_)\n",
    "print(kmeans_k8.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d28125",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "                for k in range(1, 10)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(range(1, 10), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.annotate('Elbow',\n",
    "             xy=(4, inertias[3]),\n",
    "             xytext=(0.55, 0.55),\n",
    "             textcoords='figure fraction',\n",
    "             fontsize=16,\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1)\n",
    "            )\n",
    "plt.axis([1, 8.5, 0, 1300])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundaries(kmeans_per_k[4-1], X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_score(X, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = [silhouette_score(X, model.labels_)\n",
    "                     for model in kmeans_per_k[1:]]\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(range(2, 10), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.axis([1.8, 8.5, 0.55, 0.7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "\n",
    "plt.figure(figsize=(11, 9))\n",
    "\n",
    "for k in (3, 4, 5, 6):\n",
    "    plt.subplot(2, 2, k - 2)\n",
    "    \n",
    "    y_pred = kmeans_per_k[k - 1].labels_\n",
    "    silhouette_coefficients = silhouette_samples(X, y_pred)\n",
    "\n",
    "    padding = len(X) // 30\n",
    "    pos = padding\n",
    "    ticks = []\n",
    "    for i in range(k):\n",
    "        coeffs = silhouette_coefficients[y_pred == i]\n",
    "        coeffs.sort()\n",
    "\n",
    "        color = mpl.cm.Spectral(i / k)\n",
    "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ticks.append(pos + len(coeffs) // 2)\n",
    "        pos += len(coeffs) + padding\n",
    "\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
    "    if k in (3, 5):\n",
    "        plt.ylabel(\"Cluster\")\n",
    "    \n",
    "    if k in (5, 6):\n",
    "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        plt.xlabel(\"Silhouette Coefficient\")\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "\n",
    "    plt.axvline(x=silhouette_scores[k - 2], color=\"red\", linestyle=\"--\")\n",
    "    plt.title(\"$k={}$\".format(k), fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd5efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f58d151",
   "metadata": {},
   "source": [
    "<h1>DBSCAN（density-based spatial clustering of applications with noise）</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789fe41",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e9aa6f",
   "metadata": {},
   "source": [
    "<h4>概要</h4>\n",
    "DBSCANの主な利点は、ユーザがクラスタ数を先験的に与える必要がないことと、どのクラスタにも属さない点を判別できることである<br>\n",
    "DBSCANは、クラスタはデータ中で多くの点が近接し「混んでいる」領域を構成しており、比較的空虚な領域で区切られているという考えに基づく<br>\n",
    "DBSCANには、<b>min_samples</b>と<b>eps</b>という2つのパラメータがある<br>\n",
    "1.まず適当に1つのデータポイントを選び、そのデータポイントから距離eps以内にあるすべてのデータポイントを見つける<br>\n",
    "2.その数がmin_samples以下であれば、その点はどのクラスタにも属さないノイズとなる<br>\n",
    "3.その数がmin_samples以上であれば、その点はコアサンプルと呼ばれ、新しいクラスタラベルが割り当てられる<br>\n",
    "4.3の次に、eps以内の全近傍点に対し、それらの点がまだクラスタに割り当てられていなければ、今作ったばかりの新しいクラスタラベルを割り当てる<br>\n",
    "5.近傍点がコアサンプルであれば、その近傍点をさらにテストする。これをクラスタからeps以内にコアサンプルが存在しなくなるまで繰り返す<br>\n",
    "6.5が終わると、まだ調べていない点を選んで、同じ手続きを繰り返す<br>\n",
    "最終的には3種類のデータポイントができる。コアサンプル、コアサンプルから距離eps以内にあるデータポイント（境界ポイント）、ノイズ<br>\n",
    "コアサンプルのクラスタリングとノイズになるデータポイントは、常に同じになる<br>\n",
    "境界ポイントは、複数のクラスタに属するコアサンプルの近傍点である場合、テストされるデータポイントの順番によってクラスタが変わる可能性がある<br>\n",
    "凝集型クラスタリングと同様に、DBSCANでも新しいテストデータに対する予測を行うことはできない\n",
    "\n",
    "<h4>epsとmin_samplesの影響</h4>\n",
    "epsを増やすと、より多くの点がクラスタに含まれるようになる。クラスタが大きくなるが、複数のクラスタが併合されることにもなる<br>\n",
    "min_samplesを増やすと、コアサンプルになるデータポイントが少なくなり、より多くのデータポイントがノイズになる<br>\n",
    "epsはデータポイントが「近い」ことの意味を決めるため、どちらかというとmin_samplesよりも重要だ<br>\n",
    "min_samplesの設定は、密度の低い領域にあるデータポイントがノイズとなるが、独自のクラスタになるかに影響する<br>\n",
    "従って、min_samplesは最小のクラスタのサイズを決定することになる<br>\n",
    "DBSCANではクラスタの数を明示的に設定する必要はないが、epsの設定で暗黙にクラスタ数を制御することになる\n",
    "\n",
    "<h4>スケール変換</h4>\n",
    "良いepsの値を見つけるには、StandardScalerやMinMaxScalerでスケール変換してからの方が容易なことが多い\n",
    "これらのスケール変換を行うと、全ての特徴量が同じ範囲になることが保証されるからだ\n",
    "\n",
    "DBSCANのクラスタリング結果を別の配列のインデックスに使う場合は、ノイズを表す-1の取り扱いに注意が必要だ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記例では、デフォルトのepsとmin_samplesが適していないため、全てノイズになってしまっている\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X, y = make_blobs(random_state = 0, n_samples = 12)\n",
    "\n",
    "dbscan = DBSCAN()\n",
    "clusters = dbscan.fit_predict(X)\n",
    "print(f\"Cluster memberships:\\n{clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsとmin_samplesを色々と変えて結果を見てみる\n",
    "mglearn.plots.plot_dbscan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22191ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X, y = make_moons(n_samples = 200, noise = 0.05, random_state = 0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184788b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN()\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "plt.scatter(X_scaled[:,0],X_scaled[:,1], c = clusters, cmap = mglearn.cm2, s = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143de468",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps = 0.2)\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "plt.scatter(X_scaled[:,0],X_scaled[:,1], c = clusters, cmap = mglearn.cm2, s = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d01f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps = 0.7)\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "plt.scatter(X_scaled[:,0],X_scaled[:,1], c = clusters, cmap = mglearn.cm2, s = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb0366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
